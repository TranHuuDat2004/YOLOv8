import cv2
import tempfile
import numpy as np
import streamlit as st
import time
from ultralytics import YOLO

# 1. C·∫•u h√¨nh trang
st.set_page_config(page_title="AI Speed Estimation", layout="wide")
st.title("üöó AI Speed Estimation (ƒêo t·ªëc ƒë·ªô)")
st.markdown("""
**Nguy√™n l√Ω:**
1. Tracking v·ªã tr√≠ v·∫≠t th·ªÉ theo th·ªùi gian.
2. T√≠nh kho·∫£ng c√°ch di chuy·ªÉn (pixel).
3. Chia cho th·ªùi gian (d·ª±a v√†o FPS) ƒë·ªÉ ra v·∫≠n t·ªëc.
""")

# 2. Load Model
@st.cache_resource
def load_model():
    # D√πng model l·ªõn h∆°n ch√∫t (medium) ƒë·ªÉ detect xe t·ªët h∆°n
    return YOLO('yolov8m.pt') 

try:
    model = load_model()
except Exception as e:
    st.error(f"L·ªói t·∫£i model: {e}")
    st.stop()

# 3. Sidebar
st.sidebar.header("‚öôÔ∏è C·∫•u h√¨nh ƒëo ƒë·∫°c")
conf_threshold = st.sidebar.slider("ƒê·ªô nh·∫°y (Confidence)", 0.3, 1.0, 0.5)

# QUAN TR·ªåNG: H·ªá s·ªë quy ƒë·ªïi Pixel -> M√©t
# B·∫°n c·∫ßn ∆∞·ªõc l∆∞·ª£ng: Chi·ªÅu ngang ƒë∆∞·ªùng th·ª±c t·∫ø l√† bao nhi√™u m√©t? 
# V√† tr√™n video n√≥ chi·∫øm bao nhi√™u pixel?
# V√≠ d·ª•: 1 chi·∫øc xe d√†i 4.5m, tr√™n video xe d√†i 100 pixel -> 1 m√©t = 22 pixel.
pixels_per_meter = st.sidebar.number_input("S·ªë Pixel ·ª©ng v·ªõi 1 M√©t (Calibration)", min_value=1.0, value=20.0, step=1.0)

source_radio = st.sidebar.radio("Ngu·ªìn video:", ["üìÇ Upload Video", "üì∑ Webcam"])

# 4. Bi·∫øn l∆∞u tr·ªØ t·ªëc ƒë·ªô
# C·∫•u tr√∫c: {track_id: [last_x, last_y, last_time, current_speed_kmh]}
speed_tracker = {}

st_frame = st.empty()
cap = None

if source_radio == "üìÇ Upload Video":
    uploaded_file = st.file_uploader("Ch·ªçn video giao th√¥ng", type=['mp4', 'avi', 'mov'])
    if uploaded_file:
        tfile = tempfile.NamedTemporaryFile(delete=False)
        tfile.write(uploaded_file.read())
        if st.sidebar.button("‚ñ∂Ô∏è B·∫Øt ƒë·∫ßu ƒëo t·ªëc ƒë·ªô"):
            cap = cv2.VideoCapture(tfile.name)
elif source_radio == "üì∑ Webcam":
    if st.sidebar.button("üî¥ B·∫≠t Camera"):
        cap = cv2.VideoCapture(0)

# 5. X·ª≠ l√Ω ch√≠nh
if cap is not None and cap.isOpened():
    stop_btn = st.sidebar.button("D·ª´ng l·∫°i")
    
    # L·∫•y FPS video ƒë·ªÉ t√≠nh th·ªùi gian
    fps = cap.get(cv2.CAP_PROP_FPS)
    if fps == 0: fps = 30 # Fallback n·∫øu kh√¥ng ƒë·ªçc ƒë∆∞·ª£c FPS
    
    while cap.isOpened() and not stop_btn:
        success, frame = cap.read()
        if not success: break
        
        # Resize nh·∫π ƒë·ªÉ x·ª≠ l√Ω nhanh h∆°n n·∫øu video 4K
        frame = cv2.resize(frame, (1280, 720))
        
        # Tracking (Xe h∆°i: class 2, Xe m√°y: class 3, Xe t·∫£i: class 7, Bus: 5)
        # Ho·∫∑c ƒë·ªÉ tr·ªëng classes=... ƒë·ªÉ detect t·∫•t c·∫£
        results = model.track(frame, classes=[2, 3, 5, 7], conf=conf_threshold, persist=True, verbose=False, tracker="bytetrack.yaml")
        
        if results[0].boxes.id is not None:
            boxes = results[0].boxes.xyxy.cpu().numpy()
            track_ids = results[0].boxes.id.cpu().numpy().astype(int)
            
            for box, track_id in zip(boxes, track_ids):
                x1, y1, x2, y2 = box
                cx = int((x1 + x2) / 2)
                cy = int((y1 + y2) / 2)
                # L·∫•y ƒëi·ªÉm ƒë√°y (ch√¢n xe) ƒë·ªÉ t√≠nh kho·∫£ng c√°ch ch√≠nh x√°c h∆°n t√¢m
                bottom_center = (cx, int(y2)) 
                
                current_time = time.time()
                
                speed_kmh = 0
                
                # Logic t√≠nh to√°n
                if track_id in speed_tracker:
                    prev_x, prev_y, prev_time, prev_speed = speed_tracker[track_id]
                    
                    # 1. T√≠nh kho·∫£ng c√°ch pixel (Euclidean distance)
                    pixel_dist = np.sqrt((cx - prev_x)**2 + (cy - prev_y)**2)
                    
                    # 2. Ch·ªâ t√≠nh n·∫øu xe di chuy·ªÉn ƒë·ªß nhi·ªÅu (tr√°nh rung l·∫Øc nhi·ªÖu)
                    if pixel_dist > 2: 
                        # 3. Quy ƒë·ªïi ra m√©t
                        real_dist_meters = pixel_dist / pixels_per_meter
                        
                        # 4. T√≠nh th·ªùi gian tr√¥i qua (gi√¢y)
                        # C√°ch 1: D√πng th·ªùi gian th·ª±c h·ªá th·ªëng (t·ªët cho webcam)
                        time_diff = current_time - prev_time
                        
                        # C√°ch 2: D√πng FPS video (t·ªët cho video upload) -> Ch√≠nh x√°c h∆°n
                        # time_diff = 1 / fps 
                        
                        if time_diff > 0:
                            speed_ms = real_dist_meters / time_diff # M√©t / gi√¢y
                            speed_kmh_raw = speed_ms * 3.6 # ƒê·ªïi ra km/h
                            
                            # 5. L√†m m∆∞·ª£t s·ªë li·ªáu (Moving Average) ƒë·ªÉ s·ªë kh√¥ng nh·∫£y lo·∫°n x·∫°
                            speed_kmh = 0.8 * prev_speed + 0.2 * speed_kmh_raw
                    else:
                        speed_kmh = prev_speed
                
                # C·∫≠p nh·∫≠t v·ªã tr√≠ m·ªõi
                speed_tracker[track_id] = [cx, cy, current_time, speed_kmh]
                
                # V·∫Ω l√™n h√¨nh
                label = f"ID:{track_id} {int(speed_kmh)} km/h"
                
                # ƒê·ªïi m√†u theo t·ªëc ƒë·ªô (Nhanh = ƒê·ªè, Ch·∫≠m = Xanh)
                color = (0, 255, 0)
                if speed_kmh > 40: color = (0, 165, 255) # Cam
                if speed_kmh > 70: color = (0, 0, 255)   # ƒê·ªè
                
                cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)
                cv2.putText(frame, label, (int(x1), int(y1)-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)

        # Hi·ªÉn th·ªã
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        st_frame.image(frame_rgb, channels="RGB", width=1200)

    cap.release()