import cv2
import tempfile
import numpy as np
import streamlit as st
from ultralytics import YOLO
from PIL import Image

# 1. C·∫•u h√¨nh trang
st.set_page_config(page_title="AI Posture Assistant", layout="centered")

st.title("üßò AI Posture Corrector")
st.markdown("---")

# 2. Load Model (Cache ƒë·ªÉ kh√¥ng load l·∫°i)
@st.cache_resource
def load_model():
    return YOLO('yolov8n-pose.pt')

try:
    model = load_model()
except Exception as e:
    st.error(f"L·ªói t·∫£i model: {e}")
    st.stop()

# 3. H√†m t√≠nh to√°n g√≥c
def calculate_angle(a, b, c):
    a = np.array(a) 
    b = np.array(b) 
    c = np.array(c) 
    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])
    angle = np.abs(radians*180.0/np.pi)
    if angle > 180.0: angle = 360 - angle
    return angle

def process_frame(frame, threshold):
    # Resize ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô n·∫øu ·∫£nh qu√° l·ªõn
    # frame = cv2.resize(frame, (640, 480))
    
    results = model(frame, verbose=False, conf=0.5)
    annotated_frame = frame.copy()
    status = "Unknown"
    color = (200, 200, 200)

    if results[0].keypoints.has_visible:
        keypoints = results[0].keypoints.data[0].cpu().numpy()
        
        # Ch·ªçn b√™n n√†o r√µ h∆°n (Left vs Right)
        if keypoints[3][2] > keypoints[4][2]: # So s√°nh ƒë·ªô tin c·∫≠y c·ªßa Tai
            ear, shoulder, hip = keypoints[3][:2], keypoints[5][:2], keypoints[11][:2]
        else:
            ear, shoulder, hip = keypoints[4][:2], keypoints[6][:2], keypoints[12][:2]

        angle = calculate_angle(ear, shoulder, hip)
        
        if angle < threshold:
            color = (0, 0, 255) # Red
            status = "BAD POSTURE"
        else:
            color = (0, 255, 0) # Green
            status = "GOOD"

        # V·∫Ω
        cv2.line(annotated_frame, (int(ear[0]), int(ear[1])), (int(shoulder[0]), int(shoulder[1])), (255, 255, 255), 3)
        cv2.line(annotated_frame, (int(shoulder[0]), int(shoulder[1])), (int(hip[0]), int(hip[1])), (255, 255, 255), 3)
        cv2.circle(annotated_frame, (int(shoulder[0]), int(shoulder[1])), 10, color, -1)
        
        cv2.putText(annotated_frame, f"Angle: {int(angle)}", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)
        cv2.putText(annotated_frame, status, (20, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)
    
    return annotated_frame, status

# 4. Sidebar C·∫•u h√¨nh
st.sidebar.header("‚öôÔ∏è C√†i ƒë·∫∑t")
mode = st.sidebar.radio("Ch·ªçn ch·∫ø ƒë·ªô ƒë·∫ßu v√†o:", ["üì∑ S·ª≠ d·ª•ng Webcam", "üìÇ Upload Video c√≥ s·∫µn"])
threshold = st.sidebar.slider("Ng∆∞·ª°ng c·∫£nh b√°o (G√≥c l∆∞ng)", 50, 170, 140)
st_status_box = st.sidebar.empty()

# 5. Logic x·ª≠ l√Ω ch√≠nh
st_frame_display = st.empty()

# --- CH·∫æ ƒê·ªò WEBCAM ---
if mode == "üì∑ S·ª≠ d·ª•ng Webcam":
    st.info("Nh·∫•n n√∫t b√™n d∆∞·ªõi ƒë·ªÉ k·∫øt n·ªëi Webcam.")
    start_cam = st.button("üî¥ B·∫Øt ƒë·∫ßu Webcam", use_container_width=True)
    
    if start_cam:
        # Th·ª≠ m·ªü Webcam
        cap = cv2.VideoCapture(0)
        
        # KI·ªÇM TRA NGAY: N·∫øu kh√¥ng m·ªü ƒë∆∞·ª£c -> B√°o l·ªói & Chuy·ªÉn sang Upload
        if not cap.isOpened():
            st.error("‚ùå L·ªñI: Thi·∫øt b·ªã n√†y kh√¥ng c√≥ Webcam ho·∫∑c kh√¥ng cho ph√©p truy c·∫≠p!")
            st.warning("‚ö†Ô∏è ƒêang chuy·ªÉn sang ch·∫ø ƒë·ªô Upload Video d·ª± ph√≤ng...")
            
            # --- FALLBACK: Hi·ªán ch·ªó upload ngay t·∫°i ƒë√¢y ---
            fallback_file = st.file_uploader("üìÇ H√£y ch·ªçn video m·∫´u ƒë·ªÉ thay th·∫ø:", type=['mp4', 'avi', 'mov'])
            if fallback_file is not None:
                tfile = tempfile.NamedTemporaryFile(delete=False)
                tfile.write(fallback_file.read())
                cap = cv2.VideoCapture(tfile.name)
            else:
                st.stop() # D·ª´ng l·∫°i ƒë·ª£i upload
        
        # N√∫t d·ª´ng (d√πng key ƒë·ªÉ tr√°nh tr√πng l·∫∑p)
        stop_btn = st.button("D·ª´ng l·∫°i", key="stop_webcam")
        
        # V√≤ng l·∫∑p x·ª≠ l√Ω (D√π l√† Webcam th·∫≠t hay Video fallback ƒë·ªÅu ch·∫°y ·ªü ƒë√¢y)
        while cap.isOpened():
            if stop_btn: break
            
            success, frame = cap.read()
            if not success:
                st.warning("M·∫•t t√≠n hi·ªáu video.")
                break
                
            # X·ª≠ l√Ω AI
            processed_frame, status_text = process_frame(frame, threshold)
            
            # Hi·ªÉn th·ªã
            processed_frame = cv2.cvtColor(processed_frame, cv2.COLOR_BGR2RGB)
            st_frame_display.image(processed_frame, channels="RGB", use_container_width=True)
            
            # C·∫≠p nh·∫≠t tr·∫°ng th√°i sidebar
            if status_text == "BAD POSTURE":
                st_status_box.error(status_text)
            else:
                st_status_box.success(status_text)
                
        cap.release()

# --- CH·∫æ ƒê·ªò UPLOAD VIDEO (Ch·ªß ƒë·ªông) ---
elif mode == "üìÇ Upload Video c√≥ s·∫µn":
    uploaded_file = st.file_uploader("K√©o th·∫£ video v√†o ƒë√¢y", type=['mp4', 'avi', 'mov'])
    
    if uploaded_file is not None:
        if st.button("‚ñ∂Ô∏è Ch·∫°y Video", use_container_width=True):
            tfile = tempfile.NamedTemporaryFile(delete=False)
            tfile.write(uploaded_file.read())
            
            cap = cv2.VideoCapture(tfile.name)
            
            stop_btn = st.button("D·ª´ng video")
            
            while cap.isOpened():
                if stop_btn: break
                success, frame = cap.read()
                if not success: break
                
                processed_frame, status_text = process_frame(frame, threshold)
                
                processed_frame = cv2.cvtColor(processed_frame, cv2.COLOR_BGR2RGB)
                st_frame_display.image(processed_frame, channels="RGB", use_container_width=True)
                
                if status_text == "BAD POSTURE":
                    st_status_box.error(status_text)
                else:
                    st_status_box.success(status_text)

            cap.release()