import cv2
import tempfile
import numpy as np
import streamlit as st
from collections import deque
from ultralytics import YOLO

# 1. C·∫•u h√¨nh trang
st.set_page_config(page_title="AI Pedestrian Analysis", layout="wide")
st.title("üö∂ AI Pedestrian Counting")
st.markdown("H·ªá th·ªëng ƒë·∫øm ng∆∞·ªùi ƒëi b·ªô trong video (ƒê√£ l·ªçc nhi·ªÖu ID).")

# 2. Load Model
@st.cache_resource
def load_model():
    return YOLO('yolov8n.pt')

try:
    model = load_model()
except Exception as e:
    st.error(f"L·ªói t·∫£i model: {e}")
    st.stop()

# 3. Sidebar C·∫•u h√¨nh
st.sidebar.header("‚öôÔ∏è C·∫•u h√¨nh")
conf_threshold = st.sidebar.slider("ƒê·ªô nh·∫°y (Confidence)", 0.3, 1.0, 0.5)

# Thanh tr∆∞·ª£t quan tr·ªçng ƒë·ªÉ l·ªçc nhi·ªÖu
min_hits = st.sidebar.slider(
    "S·ªë frame t·ªëi thi·ªÉu ƒë·ªÉ ƒë·∫øm (Anti-Flicker)", 
    min_value=5, max_value=60, value=20, 
    help="M·ªôt ng∆∞·ªùi ph·∫£i xu·∫•t hi·ªán li√™n t·ª•c trong N frame th√¨ m·ªõi ƒë∆∞·ª£c t√≠nh. Gi√∫p lo·∫°i b·ªè r√°c ho·∫∑c nh·∫≠n di·ªán ch·∫≠p ch·ªùn."
)

# 4. Bi·∫øn to√†n c·ª•c
track_history = {} 
total_unique_ids = set() 
id_life_count = {} # Bi·∫øn ƒë·∫øm tu·ªïi th·ªç ID

metric_placeholder = st.empty()
st_frame = st.empty()

# 5. Giao di·ªán Upload
uploaded_file = st.file_uploader("üìÇ Ch·ªçn video CCTV / Ng∆∞·ªùi ƒëi b·ªô (mp4, avi)", type=['mp4', 'avi', 'mov'])

if uploaded_file:
    # L∆∞u file t·∫°m
    tfile = tempfile.NamedTemporaryFile(delete=False)
    tfile.write(uploaded_file.read())
    
    if st.button("‚ñ∂Ô∏è B·∫Øt ƒë·∫ßu ph√¢n t√≠ch"):
        cap = cv2.VideoCapture(tfile.name)
        
        if cap.isOpened():
            stop_btn = st.button("D·ª´ng l·∫°i")
            
            # Progress bar
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            progress_bar = st.progress(0)
            frame_count = 0
            
            while cap.isOpened() and not stop_btn:
                success, frame = cap.read()
                if not success: break
                
                frame_count += 1
                if frame_count % 5 == 0: # C·∫≠p nh·∫≠t thanh ti·∫øn tr√¨nh m·ªói 5 frame ƒë·ªÉ ƒë·ª° lag
                    progress_bar.progress(frame_count / total_frames)

                overlay = frame.copy()
                
                # Tracking
                results = model.track(frame, classes=[0], conf=conf_threshold, persist=True, tracker="bytetrack.yaml", verbose=False)
                
                if results[0].boxes.id is not None:
                    boxes = results[0].boxes.xyxy.cpu().numpy()
                    track_ids = results[0].boxes.id.cpu().numpy().astype(int)
                    
                    for box, track_id in zip(boxes, track_ids):
                        x1, y1, x2, y2 = box
                        
                        # --- LOGIC CH·ªêNG NHI·ªÑU (ANTI-FLICKER) ---
                        # 1. TƒÉng tu·ªïi th·ªç ID
                        id_life_count[track_id] = id_life_count.get(track_id, 0) + 1
                        
                        color = (0, 255, 0) # Xanh (Ch∆∞a ƒë·∫øm)
                        status_text = "Tracking..."
                        
                        # 2. Ch·ªâ ƒê·∫æM khi ID t·ªìn t·∫°i ƒë·ªß l√¢u ( > min_hits)
                        if id_life_count[track_id] > min_hits:
                            total_unique_ids.add(track_id)
                            color = (0, 0, 255) # ƒê·ªè (ƒê√£ ƒë·∫øm)
                            status_text = f"ID:{track_id}"
                            
                            # V·∫Ω ƒë∆∞·ªùng ƒëi (Heatmap)
                            cx, cy = int((x1 + x2) / 2), int((y1 + y2) / 2)
                            if track_id not in track_history:
                                track_history[track_id] = deque(maxlen=40)
                            track_history[track_id].append((cx, cy))
                            
                            points = np.hstack(track_history[track_id]).astype(np.int32).reshape((-1, 1, 2))
                            cv2.polylines(overlay, [points], isClosed=False, color=(255, 255, 0), thickness=3)

                        # V·∫Ω Box
                        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)
                        # Hi·ªÉn th·ªã s·ªë frame ƒë√£ t·ªìn t·∫°i ƒë·ªÉ debug d·ªÖ h∆°n
                        cv2.putText(frame, f"{status_text} ({id_life_count[track_id]})", (int(x1), int(y1)-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

                # G·ªôp l·ªõp ph·ªß
                frame = cv2.addWeighted(overlay, 0.4, frame, 0.6, 0)

                # Hi·ªÉn th·ªã k·∫øt qu·∫£
                metric_placeholder.metric("üë• T·ªïng s·ªë ng∆∞·ªùi (ƒê√£ l·ªçc nhi·ªÖu)", len(total_unique_ids))
                
                # Resize ƒë·ªÉ hi·ªÉn th·ªã m∆∞·ª£t h∆°n tr√™n web
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                st_frame.image(frame_rgb, channels="RGB", width=1000)

            cap.release()
            st.success("ƒê√£ ph√¢n t√≠ch xong video!")